{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a20c0a0-8d5d-42e9-adf9-0480a103b23e",
   "metadata": {},
   "source": [
    "# PredictStudentsDropoutAndAcademicSuccess\n",
    "\n",
    "# Polytechnic Institute of Portalegre\n",
    "\n",
    "### TableOfContents\n",
    "\n",
    "* [Initialization](#Initialization)\n",
    "\n",
    "* [RandomForest](#RandomForest)\n",
    "\n",
    "* [Next](#Next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9e4a7-0cc3-4b1d-a0ea-5d343abd6579",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initialization\n",
    "[TableOfContents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8e4fb06-213d-4c72-b32e-fe59da846943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "#--------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score\n",
    "#--------------------------------------------------\n",
    "\n",
    "#global constants\n",
    "#--------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "#load csv\n",
    "#--------------------------------------------------\n",
    "DF = pd.read_csv(\"PredictStudentsDropoutAndAcademicSuccess.csv\", sep=\";\")\n",
    "df_rf = pd.read_csv(\"PredictStudentsDropoutAndAcademicSuccess.csv\", sep=\";\")\n",
    "df_02 = pd.read_csv(\"PredictStudentsDropoutAndAcademicSuccess.csv\", sep=\";\")\n",
    "df_03 = pd.read_csv(\"PredictStudentsDropoutAndAcademicSuccess.csv\", sep=\";\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "#data mapping\n",
    "#--------------------------------------------------\n",
    "# Function to convert col to camelCase\n",
    "conversion_dict = {\n",
    "    \"Marital status\": \"maritalStatus\",\n",
    "    \"Application mode\": \"applicationMode\",\n",
    "    \"Application order\": \"applicationOrder\",\n",
    "    \"Course\": \"course\",\n",
    "    \"Daytime/evening attendance\": \"daytimeEveningAttendance\",\n",
    "    \"Previous qualification\": \"previousQualification\",\n",
    "    \"Previous qualification (grade)\": \"previousQualificationGrade\",\n",
    "    \"Nacionality\": \"nationality\",\n",
    "    \"Mothers qualification\": \"motherQualification\",\n",
    "    \"Fathers qualification\": \"fatherQualification\",\n",
    "    \"Mothers occupation\": \"motherOccupation\",\n",
    "    \"Fathers occupation\": \"fatherOccupation\",\n",
    "    \"Admission grade\": \"admissionGrade\",\n",
    "    \"Displaced\": \"displaced\",\n",
    "    \"Educational special needs\": \"educationalSpecialNeeds\",\n",
    "    \"Debtor\": \"debtor\",\n",
    "    \"Tuition fees up to date\": \"tuitionFeesUpToDate\",\n",
    "    \"Gender\": \"gender\",\n",
    "    \"Scholarship holder\": \"scholarshipHolder\",\n",
    "    \"Age at enrollment\": \"ageAtEnrollment\",\n",
    "    \"International\": \"international\",\n",
    "    \"Curricular units 1st sem (credited)\": \"curricularUnits1stSemCredited\",\n",
    "    \"Curricular units 1st sem (enrolled)\": \"curricularUnits1stSemEnrolled\",\n",
    "    \"Curricular units 1st sem (evaluations)\": \"curricularUnits1stSemEvaluations\",\n",
    "    \"Curricular units 1st sem (approved)\": \"curricularUnits1stSemApproved\",\n",
    "    \"Curricular units 1st sem (grade)\": \"curricularUnits1stSemGrade\",\n",
    "    \"Curricular units 1st sem (without evaluations)\": \"curricularUnits1stSemWithoutEvaluations\",\n",
    "    \"Curricular units 2nd sem (credited)\": \"curricularUnits2ndSemCredited\",\n",
    "    \"Curricular units 2nd sem (enrolled)\": \"curricularUnits2ndSemEnrolled\",\n",
    "    \"Curricular units 2nd sem (evaluations)\": \"curricularUnits2ndSemEvaluations\",\n",
    "    \"Curricular units 2nd sem (approved)\": \"curricularUnits2ndSemApproved\",\n",
    "    \"Curricular units 2nd sem (grade)\": \"curricularUnits2ndSemGrade\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\": \"curricularUnits2ndSemWithoutEvaluations\",\n",
    "    \"Unemployment rate\": \"unemploymentRate\",\n",
    "    \"Inflation rate\": \"inflationRate\",\n",
    "    \"GDP\": \"gdp\",\n",
    "    \"Target\": \"target\"\n",
    "}\n",
    "\n",
    "# Marital Status\n",
    "maritalStatus = {\n",
    "    1: \"single\",\n",
    "    2: \"married\",\n",
    "    3: \"widower\",\n",
    "    4: \"divorced\",\n",
    "    5: \"facto union\",\n",
    "    6: \"legally separated\"\n",
    "}\n",
    "\n",
    "# Application Mode\n",
    "applicationMode = {\n",
    "    1: \"1st phase - general contingent\",\n",
    "    2: \"Ordinance No. 612/93\",\n",
    "    5: \"1st phase - special contingent (Azores Island)\",\n",
    "    7: \"Holders of other higher courses\",\n",
    "    10: \"Ordinance No. 854-B/99\",\n",
    "    15: \"International student (bachelor)\",\n",
    "    16: \"1st phase - special contingent (Madeira Island)\",\n",
    "    17: \"2nd phase - general contingent\",\n",
    "    18: \"3rd phase - general contingent\",\n",
    "    26: \"Ordinance No. 533-A/99, item b2) (Different Plan)\",\n",
    "    27: \"Ordinance No. 533-A/99, item b3 (Other Institution)\",\n",
    "    39: \"Over 23 years old\",\n",
    "    42: \"Transfer\",\n",
    "    43: \"Change of course\",\n",
    "    44: \"Technological specialization diploma holders\",\n",
    "    51: \"Change of institution/course\",\n",
    "    53: \"Short cycle diploma holders\",\n",
    "    57: \"Change of institution/course (International)\"\n",
    "}\n",
    "\n",
    "# Course\n",
    "course = {\n",
    "    33: \"Biofuel Production Technologies\",\n",
    "    171: \"Animation and Multimedia Design\",\n",
    "    8014: \"Social Service (evening attendance)\",\n",
    "    9003: \"Agronomy\",\n",
    "    9070: \"Communication Design\",\n",
    "    9085: \"Veterinary Nursing\",\n",
    "    9119: \"Informatics Engineering\",\n",
    "    9130: \"Equinculture\",\n",
    "    9147: \"Management\",\n",
    "    9238: \"Social Service\",\n",
    "    9254: \"Tourism\",\n",
    "    9500: \"Nursing\",\n",
    "    9556: \"Oral Hygiene\",\n",
    "    9670: \"Advertising and Marketing Management\",\n",
    "    9773: \"Journalism and Communication\",\n",
    "    9853: \"Basic Education\",\n",
    "    9991: \"Management (evening attendance)\"\n",
    "}\n",
    "\n",
    "# Nationality\n",
    "nationality = {\n",
    "    1: \"Portuguese\",\n",
    "    2: \"German\",\n",
    "    6: \"Spanish\",\n",
    "    11: \"Italian\",\n",
    "    13: \"Dutch\",\n",
    "    14: \"English\",\n",
    "    17: \"Lithuanian\",\n",
    "    21: \"Angolan\",\n",
    "    22: \"Cape Verdean\",\n",
    "    24: \"Guinean\",\n",
    "    25: \"Mozambican\",\n",
    "    26: \"Santomean\",\n",
    "    32: \"Turkish\",\n",
    "    41: \"Brazilian\",\n",
    "    62: \"Romanian\",\n",
    "    100: \"Moldova (Republic of)\",\n",
    "    101: \"Mexican\",\n",
    "    103: \"Ukrainian\",\n",
    "    105: \"Russian\",\n",
    "    108: \"Cuban\",\n",
    "    109: \"Colombian\"\n",
    "}\n",
    "\n",
    "# Binary attributes\n",
    "daytimeEveningAttendance = {1: \"daytime\", 0: \"evening\"}\n",
    "displaced = {1: \"yes\", 0: \"no\"}\n",
    "educationalSpecialNeeds = {1: \"yes\", 0: \"no\"}\n",
    "debtor = {1: \"yes\", 0: \"no\"}\n",
    "tuitionFeesUpToDate = {1: \"yes\", 0: \"no\"}\n",
    "gender = {1: \"male\", 0: \"female\"}\n",
    "scholarshipHolder = {1: \"yes\", 0: \"no\"}\n",
    "international = {1: \"yes\", 0: \"no\"}\n",
    "\n",
    "# Sample dictionary to map macro data triplets to a year\n",
    "econ_to_year = {\n",
    "    (10.8, 1.4, 1.74): 2010,\n",
    "    (13.9, -0.3, 0.79): 2011,\n",
    "    (9.4, -0.8, -3.12): 2012,\n",
    "    (16.2, 0.3, -0.92): 2013,\n",
    "    (15.5, 2.8, -4.06): 2014,\n",
    "    (8.9, 1.4, 3.51): 2015,\n",
    "    (12.7, 3.7, -1.70): 2016,\n",
    "    (11.1, 0.6, 2.02): 2017,\n",
    "    (7.6, 2.6, 0.32): 2018,\n",
    "    (12.4, 0.5, 1.79): 2019\n",
    "}\n",
    "\n",
    "# Target\n",
    "targetMap = {\n",
    "    \"Dropout\": 0,\n",
    "    \"Enrolled\": 1,\n",
    "    \"Graduate\": 2,\n",
    "}\n",
    "\n",
    "targetMapReverse = {v: k for k, v in targetMap.items()}\n",
    "\n",
    "# Previous Qualification\n",
    "previousQualification = {\n",
    "    1: \"Secondary education\",\n",
    "    2: \"Higher education - bachelor's degree\",\n",
    "    3: \"Higher education - degree\",\n",
    "    4: \"Higher education - master's\",\n",
    "    5: \"Higher education - doctorate\",\n",
    "    6: \"Frequency of higher education\",\n",
    "    9: \"12th year of schooling - not completed\",\n",
    "    10: \"11th year of schooling - not completed\",\n",
    "    12: \"Other - 11th year of schooling\",\n",
    "    14: \"10th year of schooling\",\n",
    "    15: \"10th year of schooling - not completed\",\n",
    "    19: \"Basic education 3rd cycle (9th/10th/11th year) or equiv.\",\n",
    "    38: \"Basic education 2nd cycle (6th/7th/8th year) or equiv.\",\n",
    "    39: \"Technological specialization course\",\n",
    "    40: \"Higher education - degree (1st cycle)\",\n",
    "    42: \"Professional higher technical course\",\n",
    "    43: \"Higher education - master (2nd cycle)\"\n",
    "}\n",
    "\n",
    "# Mother's Qualification\n",
    "motherQualification = {\n",
    "    1: \"Secondary Education - 12th Year of Schooling or Eq.\",\n",
    "    2: \"Higher Education - Bachelor's Degree\",\n",
    "    3: \"Higher Education - Degree\",\n",
    "    4: \"Higher Education - Master's\",\n",
    "    5: \"Higher Education - Doctorate\",\n",
    "    6: \"Frequency of Higher Education\",\n",
    "    9: \"12th Year of Schooling - Not Completed\",\n",
    "    10: \"11th Year of Schooling - Not Completed\",\n",
    "    11: \"7th Year (Old)\",\n",
    "    12: \"Other - 11th Year of Schooling\",\n",
    "    14: \"10th Year of Schooling\",\n",
    "    18: \"General commerce course\",\n",
    "    19: \"Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv.\",\n",
    "    22: \"Technical-professional course\",\n",
    "    26: \"7th year of schooling\",\n",
    "    27: \"2nd cycle of the general high school course\",\n",
    "    29: \"9th Year of Schooling - Not Completed\",\n",
    "    30: \"8th year of schooling\",\n",
    "    34: \"Unknown\",\n",
    "    35: \"Can't read or write\",\n",
    "    36: \"Can read without having a 4th year of schooling\",\n",
    "    37: \"Basic education 1st cycle (4th/5th year) or equiv.\",\n",
    "    38: \"Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv.\",\n",
    "    39: \"Technological specialization course\",\n",
    "    40: \"Higher education - degree (1st cycle)\",\n",
    "    41: \"Specialized higher studies course\",\n",
    "    42: \"Professional higher technical course\",\n",
    "    43: \"Higher Education - Master (2nd cycle)\",\n",
    "    44: \"Higher Education - Doctorate (3rd cycle)\"\n",
    "}\n",
    "\n",
    "# Father's Qualification\n",
    "fatherQualification = {\n",
    "    1: \"Secondary Education - 12th Year of Schooling or Eq.\",\n",
    "    2: \"Higher Education - Bachelor's Degree\",\n",
    "    3: \"Higher Education - Degree\",\n",
    "    4: \"Higher Education - Master's\",\n",
    "    5: \"Higher Education - Doctorate\",\n",
    "    6: \"Frequency of Higher Education\",\n",
    "    9: \"12th Year of Schooling - Not Completed\",\n",
    "    10: \"11th Year of Schooling - Not Completed\",\n",
    "    11: \"7th Year (Old)\",\n",
    "    12: \"Other - 11th Year of Schooling\",\n",
    "    13: \"2nd year complementary high school course\",\n",
    "    14: \"10th Year of Schooling\",\n",
    "    18: \"General commerce course\",\n",
    "    19: \"Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv.\",\n",
    "    20: \"Complementary High School Course\",\n",
    "    22: \"Technical-professional course\",\n",
    "    25: \"Complementary High School Course - not concluded\",\n",
    "    26: \"7th year of schooling\",\n",
    "    27: \"2nd cycle of the general high school course\",\n",
    "    29: \"9th Year of Schooling - Not Completed\",\n",
    "    30: \"8th year of schooling\",\n",
    "    31: \"General Course of Administration and Commerce\",\n",
    "    33: \"Supplementary Accounting and Administration\",\n",
    "    34: \"Unknown\",\n",
    "    35: \"Can't read or write\",\n",
    "    36: \"Can read without having a 4th year of schooling\",\n",
    "    37: \"Basic education 1st cycle (4th/5th year) or equiv.\",\n",
    "    38: \"Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv.\",\n",
    "    39: \"Technological specialization course\",\n",
    "    40: \"Higher education - degree (1st cycle)\",\n",
    "    41: \"Specialized higher studies course\",\n",
    "    42: \"Professional higher technical course\",\n",
    "    43: \"Higher Education - Master (2nd cycle)\",\n",
    "    44: \"Higher Education - Doctorate (3rd cycle)\"\n",
    "}\n",
    "\n",
    "# Combine Qualification\n",
    "combineQualification = {\n",
    "    1: \"Secondary Education - 12th Year of Schooling or Eq.\",\n",
    "    2: \"Higher Education - Bachelor's Degree\",\n",
    "    3: \"Higher Education - Degree\",\n",
    "    4: \"Higher Education - Master's\",\n",
    "    5: \"Higher Education - Doctorate\",\n",
    "    6: \"Frequency of Higher Education\",\n",
    "    9: \"12th Year of Schooling - Not Completed\",\n",
    "    10: \"11th Year of Schooling - Not Completed\",\n",
    "    11: \"7th Year (Old)\",\n",
    "    12: \"Other - 11th Year of Schooling\",\n",
    "    13: \"2nd year complementary high school course\",\n",
    "    14: \"10th Year of Schooling\",\n",
    "    15: \"10th Year of Schooling - Not Completed\",\n",
    "    18: \"General commerce course\",\n",
    "    19: \"Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv.\",\n",
    "    20: \"Complementary High School Course\",\n",
    "    22: \"Technical-professional course\",\n",
    "    25: \"Complementary High School Course - not concluded\",\n",
    "    26: \"7th year of schooling\",\n",
    "    27: \"2nd cycle of the general high school course\",\n",
    "    29: \"9th Year of Schooling - Not Completed\",\n",
    "    30: \"8th year of schooling\",\n",
    "    31: \"General Course of Administration and Commerce\",\n",
    "    33: \"Supplementary Accounting and Administration\",\n",
    "    34: \"Unknown\",\n",
    "    35: \"Can't read or write\",\n",
    "    36: \"Can read without having a 4th year of schooling\",\n",
    "    37: \"Basic education 1st cycle (4th/5th year) or equiv.\",\n",
    "    38: \"Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv.\",\n",
    "    39: \"Technological specialization course\",\n",
    "    40: \"Higher education - degree (1st cycle)\",\n",
    "    41: \"Specialized higher studies course\",\n",
    "    42: \"Professional higher technical course\",\n",
    "    43: \"Higher Education - Master (2nd cycle)\",\n",
    "    44: \"Higher Education - Doctorate (3rd cycle)\"\n",
    "}\n",
    "\n",
    "# Ordinal grouping mapping\n",
    "qualificationOrdinal = {\n",
    "    **{code: 0 for code in [34, 35]}, #No documented education\n",
    "    **{code: 1 for code in [11, 12, 26, 27, 29, 30, 31, 37, 38, 36]}, #Basic/primary schooling\n",
    "    **{code: 2 for code in [9, 10, 14, 15, 13, 18, 20, 22, 25, 19, 33, 41]}, #Interrupted or completed\n",
    "    **{code: 3 for code in [39, 42]}, #Technological or sub-degree\n",
    "    **{code: 4 for code in [1, 2, 3, 40, 4, 43, 5, 44, 6]} #Degree and beyond\n",
    "}\n",
    "\n",
    "# Ordinal grouping mapping name\n",
    "qualificationOrdinalName = {\n",
    "    0: \"None. No documented education\",\n",
    "    1: \"Basic. Basic/primary schooling\",\n",
    "    2: \"Secondary. Interrupted or completed\",\n",
    "    3: \"Post-Secondary. Technological or sub-degree\",\n",
    "    4: \"Higher Ed. Degree and beyond\",\n",
    "}\n",
    "\n",
    "# Mother's Occupation\n",
    "motherOccupation = {\n",
    "    0: \"Student\",\n",
    "    1: \"Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers\",\n",
    "    2: \"Specialists in Intellectual and Scientific Activities\",\n",
    "    3: \"Intermediate Level Technicians and Professions\",\n",
    "    4: \"Administrative staff\",\n",
    "    5: \"Personal Services, Security and Safety Workers and Sellers\",\n",
    "    6: \"Farmers and Skilled Workers in Agriculture, Fisheries and Forestry\",\n",
    "    7: \"Skilled Workers in Industry, Construction and Craftsmen\",\n",
    "    8: \"Installation and Machine Operators and Assembly Workers\",\n",
    "    9: \"Unskilled Workers\",\n",
    "    10: \"Armed Forces Professions\",\n",
    "    90: \"Other Situation\",\n",
    "    99: \"(blank)\",\n",
    "    122: \"Health professionals\",\n",
    "    123: \"teachers\",\n",
    "    125: \"Specialists in information and communication technologies (ICT)\",\n",
    "    131: \"Intermediate level science and engineering technicians and professions\",\n",
    "    132: \"Technicians and professionals, of intermediate level of health\",\n",
    "    134: \"Intermediate level technicians from legal, social, sports, cultural and similar services\",\n",
    "    141: \"Office workers, secretaries in general and data processing operators\",\n",
    "    143: \"Data, accounting, statistical, financial services and registry-related operators\",\n",
    "    144: \"Other administrative support staff\",\n",
    "    151: \"personal service workers\",\n",
    "    152: \"sellers\",\n",
    "    153: \"Personal care workers and the like\",\n",
    "    171: \"Skilled construction workers and the like, except electricians\",\n",
    "    173: \"Skilled workers in printing, precision instrument manufacturing, jewelers, artisans and the like\",\n",
    "    175: \"Workers in food processing, woodworking, clothing and other industries and crafts\",\n",
    "    191: \"cleaning workers\",\n",
    "    192: \"Unskilled workers in agriculture, animal production, fisheries and forestry\",\n",
    "    193: \"Unskilled workers in extractive industry, construction, manufacturing and transport\",\n",
    "    194: \"Meal preparation assistants\"\n",
    "}\n",
    "\n",
    "# Father's Occupation\n",
    "fatherOccupation = {\n",
    "    0: \"Student\",\n",
    "    1: \"Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers\",\n",
    "    2: \"Specialists in Intellectual and Scientific Activities\",\n",
    "    3: \"Intermediate Level Technicians and Professions\",\n",
    "    4: \"Administrative staff\",\n",
    "    5: \"Personal Services, Security and Safety Workers and Sellers\",\n",
    "    6: \"Farmers and Skilled Workers in Agriculture, Fisheries and Forestry\",\n",
    "    7: \"Skilled Workers in Industry, Construction and Craftsmen\",\n",
    "    8: \"Installation and Machine Operators and Assembly Workers\",\n",
    "    9: \"Unskilled Workers\",\n",
    "    10: \"Armed Forces Professions\",\n",
    "    90: \"Other Situation\",\n",
    "    99: \"(blank)\",\n",
    "    101: \"Armed Forces Officers\",\n",
    "    102: \"Armed Forces Sergeants\",\n",
    "    103: \"Other Armed Forces personnel\",\n",
    "    112: \"Directors of administrative and commercial services\",\n",
    "    114: \"Hotel, catering, trade and other services directors\",\n",
    "    121: \"Specialists in the physical sciences, mathematics, engineering and related techniques\",\n",
    "    122: \"Health professionals\",\n",
    "    123: \"teachers\",\n",
    "    124: \"Specialists in finance, accounting, administrative organization, public and commercial relations\",\n",
    "    131: \"Intermediate level science and engineering technicians and professions\",\n",
    "    132: \"Technicians and professionals, of intermediate level of health\",\n",
    "    134: \"Intermediate level technicians from legal, social, sports, cultural and similar services\",\n",
    "    135: \"Information and communication technology technicians\",\n",
    "    141: \"Office workers, secretaries in general and data processing operators\",\n",
    "    143: \"Data, accounting, statistical, financial services and registry-related operators\",\n",
    "    144: \"Other administrative support staff\",\n",
    "    151: \"personal service workers\",\n",
    "    152: \"sellers\",\n",
    "    153: \"Personal care workers and the like\",\n",
    "    154: \"Protection and security services personnel\",\n",
    "    161: \"Market-oriented farmers and skilled agricultural and animal production workers\",\n",
    "    163: \"Farmers, livestock keepers, fishermen, hunters and gatherers, subsistence\",\n",
    "    171: \"Skilled construction workers and the like, except electricians\",\n",
    "    172: \"Skilled workers in metallurgy, metalworking and similar\",\n",
    "    174: \"Skilled workers in electricity and electronics\",\n",
    "    175: \"Workers in food processing, woodworking, clothing and other industries and crafts\",\n",
    "    181: \"Fixed plant and machine operators\",\n",
    "    182: \"assembly workers\",\n",
    "    183: \"Vehicle drivers and mobile equipment operators\",\n",
    "    192: \"Unskilled workers in agriculture, animal production, fisheries and forestry\",\n",
    "    193: \"Unskilled workers in extractive industry, construction, manufacturing and transport\",\n",
    "    194: \"Meal preparation assistants\",\n",
    "    195: \"Street vendors (except food) and street service providers\"\n",
    "}\n",
    "\n",
    "# Combine Occupation\n",
    "combineOccupation = {\n",
    "    0: \"Student\",\n",
    "    1: \"Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers\",\n",
    "    2: \"Specialists in Intellectual and Scientific Activities\",\n",
    "    3: \"Intermediate Level Technicians and Professions\",\n",
    "    4: \"Administrative staff\",\n",
    "    5: \"Personal Services, Security and Safety Workers and Sellers\",\n",
    "    6: \"Farmers and Skilled Workers in Agriculture, Fisheries and Forestry\",\n",
    "    7: \"Skilled Workers in Industry, Construction and Craftsmen\",\n",
    "    8: \"Installation and Machine Operators and Assembly Workers\",\n",
    "    9: \"Unskilled Workers\",\n",
    "    10: \"Armed Forces Professions\",\n",
    "    90: \"Other Situation\",\n",
    "    99: \"(blank)\",\n",
    "    101: \"Armed Forces Officers\",\n",
    "    102: \"Armed Forces Sergeants\",\n",
    "    103: \"Other Armed Forces personnel\",\n",
    "    112: \"Directors of administrative and commercial services\",\n",
    "    114: \"Hotel, catering, trade and other services directors\",\n",
    "    121: \"Specialists in the physical sciences, mathematics, engineering and related techniques\",\n",
    "    122: \"Health professionals\",\n",
    "    123: \"teachers\",\n",
    "    124: \"Specialists in finance, accounting, administrative organization, public and commercial relations\",\n",
    "    125: \"Specialists in information and communication technologies (ICT)\",\n",
    "    131: \"Intermediate level science and engineering technicians and professions\",\n",
    "    132: \"Technicians and professionals, of intermediate level of health\",\n",
    "    134: \"Intermediate level technicians from legal, social, sports, cultural and similar services\",\n",
    "    135: \"Information and communication technology technicians\",\n",
    "    141: \"Office workers, secretaries in general and data processing operators\",\n",
    "    143: \"Data, accounting, statistical, financial services and registry-related operators\",\n",
    "    144: \"Other administrative support staff\",\n",
    "    151: \"personal service workers\",\n",
    "    152: \"sellers\",\n",
    "    153: \"Personal care workers and the like\",\n",
    "    154: \"Protection and security services personnel\",\n",
    "    161: \"Market-oriented farmers and skilled agricultural and animal production workers\",\n",
    "    163: \"Farmers, livestock keepers, fishermen, hunters and gatherers, subsistence\",\n",
    "    171: \"Skilled construction workers and the like, except electricians\",\n",
    "    172: \"Skilled workers in metallurgy, metalworking and similar\",\n",
    "    173: \"Skilled workers in printing, precision instrument manufacturing, jewelers, artisans and the like\",\n",
    "    174: \"Skilled workers in electricity and electronics\",\n",
    "    175: \"Workers in food processing, woodworking, clothing and other industries and crafts\",\n",
    "    181: \"Fixed plant and machine operators\",\n",
    "    182: \"assembly workers\",\n",
    "    183: \"Vehicle drivers and mobile equipment operators\",\n",
    "    191: \"cleaning workers\",\n",
    "    192: \"Unskilled workers in agriculture, animal production, fisheries and forestry\",\n",
    "    193: \"Unskilled workers in extractive industry, construction, manufacturing and transport\",\n",
    "    194: \"Meal preparation assistants\",\n",
    "    195: \"Street vendors (except food) and street service providers\"\n",
    "}\n",
    "\n",
    "# Occupation Income Level\n",
    "occupationOrdinal = {\n",
    "    **{code: 0 for code in [0, 90, 99]},\n",
    "    **{code: 1 for code in [9, 191, 192, 193, 194, 195, 163]},\n",
    "    **{code: 2 for code in [6, 7, 171, 172, 173, 174, 175, 8, 181, 182, 183, 152, 153, 154, 151]},\n",
    "    **{code: 3 for code in [3, 131, 132, 134, 135, 4, 141, 143, 144, 5, 10, 101, 102, 103, 161]},\n",
    "    **{code: 4 for code in [2, 121, 122, 123, 124, 125]},\n",
    "    **{code: 5 for code in [1, 112, 114]}\n",
    "}\n",
    "\n",
    "# Occupation Income Level Name\n",
    "occupationOrdinalName = {\n",
    "    0: \"None/Unknown\",\n",
    "    1: \"Low income\",\n",
    "    2: \"Lower-Middle income\",\n",
    "    3: \"Middle income\",\n",
    "    4: \"Upper-Middle income\",\n",
    "    5: \"High income\"\n",
    "}\n",
    "#--------------------------------------------------\n",
    "\n",
    "#common functions\n",
    "#--------------------------------------------------\n",
    "globalHeader = \"\"\n",
    "isHeader = True\n",
    "def __________section__________(header = globalHeader, width = 50):\n",
    "    global globalHeader, isHeader\n",
    "    \n",
    "    GREEN = \"\\033[32m\"\n",
    "    RED = \"\\033[31m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    \n",
    "    if isHeader:\n",
    "        bar = \">\" * width\n",
    "        print(GREEN + BOLD + \"\\n\" + bar + RESET)\n",
    "        print(GREEN + BOLD + f\">[SECTION]{header.upper()}\" + RESET)\n",
    "        globalHeader = header\n",
    "        isHeader = False\n",
    "\n",
    "    else:\n",
    "        bar = \"<\" * width\n",
    "        print(RED + BOLD + f\"<[SECTION]{globalHeader.upper()}\" + RESET)\n",
    "        print(RED + BOLD + bar + \"\\n\" + RESET)\n",
    "        isHeader = True\n",
    "\n",
    "def _c_(comment):\n",
    "\n",
    "    BLUE = \"\\033[34m\"\n",
    "    ITALIC = \"\\033[3m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    print(BLUE + ITALIC + f\"-------[C]{comment.lower()}\" + RESET)\n",
    "        \n",
    "def nanCheck():\n",
    "    _c_(\"Check how many missing values per column\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    _c_(\"Show only columns that have missing values\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "    _c_(\"Check if any missing value exists in the entire DataFrame\")\n",
    "    print(df.isnull().values.any())\n",
    "\n",
    "    _c_(\"List all rows that contain any NaN\")\n",
    "    print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f75c6-b3ba-42d3-9a18-8e8574170fd9",
   "metadata": {},
   "source": [
    "# RandomForest\n",
    "[TableOfContents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c74b41e1-752e-458c-8c1d-22ca3e2ebd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]GENERAL CHECK\u001b[0m\n",
      "\u001b[34m\u001b[3m-------[C]check type\u001b[0m\n",
      "target    object\n",
      "dtype: object\n",
      "\u001b[34m\u001b[3m-------[C]check how many missing values per column\u001b[0m\n",
      "maritalStatus                              0\n",
      "applicationMode                            0\n",
      "applicationOrder                           0\n",
      "course                                     0\n",
      "daytimeEveningAttendance                   0\n",
      "previousQualification                      0\n",
      "previousQualificationGrade                 0\n",
      "nationality                                0\n",
      "motherQualification                        0\n",
      "fatherQualification                        0\n",
      "motherOccupation                           0\n",
      "fatherOccupation                           0\n",
      "admissionGrade                             0\n",
      "displaced                                  0\n",
      "educationalSpecialNeeds                    0\n",
      "debtor                                     0\n",
      "tuitionFeesUpToDate                        0\n",
      "gender                                     0\n",
      "scholarshipHolder                          0\n",
      "ageAtEnrollment                            0\n",
      "international                              0\n",
      "curricularUnits1stSemCredited              0\n",
      "curricularUnits1stSemEnrolled              0\n",
      "curricularUnits1stSemEvaluations           0\n",
      "curricularUnits1stSemApproved              0\n",
      "curricularUnits1stSemGrade                 0\n",
      "curricularUnits1stSemWithoutEvaluations    0\n",
      "curricularUnits2ndSemCredited              0\n",
      "curricularUnits2ndSemEnrolled              0\n",
      "curricularUnits2ndSemEvaluations           0\n",
      "curricularUnits2ndSemApproved              0\n",
      "curricularUnits2ndSemGrade                 0\n",
      "curricularUnits2ndSemWithoutEvaluations    0\n",
      "unemploymentRate                           0\n",
      "inflationRate                              0\n",
      "gdp                                        0\n",
      "target                                     0\n",
      "dtype: int64\n",
      "\u001b[34m\u001b[3m-------[C]show only columns that have missing values\u001b[0m\n",
      "Series([], dtype: int64)\n",
      "\u001b[34m\u001b[3m-------[C]check if any missing value exists in the entire dataframe\u001b[0m\n",
      "False\n",
      "\u001b[34m\u001b[3m-------[C]list all rows that contain any nan\u001b[0m\n",
      "Empty DataFrame\n",
      "Columns: [maritalStatus, applicationMode, applicationOrder, course, daytimeEveningAttendance, previousQualification, previousQualificationGrade, nationality, motherQualification, fatherQualification, motherOccupation, fatherOccupation, admissionGrade, displaced, educationalSpecialNeeds, debtor, tuitionFeesUpToDate, gender, scholarshipHolder, ageAtEnrollment, international, curricularUnits1stSemCredited, curricularUnits1stSemEnrolled, curricularUnits1stSemEvaluations, curricularUnits1stSemApproved, curricularUnits1stSemGrade, curricularUnits1stSemWithoutEvaluations, curricularUnits2ndSemCredited, curricularUnits2ndSemEnrolled, curricularUnits2ndSemEvaluations, curricularUnits2ndSemApproved, curricularUnits2ndSemGrade, curricularUnits2ndSemWithoutEvaluations, unemploymentRate, inflationRate, gdp, target]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 37 columns]\n",
      "\u001b[31m\u001b[1m<[SECTION]GENERAL CHECK\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]ECON AND YEAR\u001b[0m\n",
      "Missing year: 0\n",
      "\u001b[34m\u001b[3m-------[C]check how many missing values per column\u001b[0m\n",
      "maritalStatus                                0\n",
      "applicationMode                              0\n",
      "applicationOrder                             0\n",
      "course                                       0\n",
      "daytimeEveningAttendance                     0\n",
      "previousQualification                        0\n",
      "previousQualificationGrade                   0\n",
      "nationality                                  0\n",
      "motherQualification                          0\n",
      "fatherQualification                          0\n",
      "motherOccupation                             0\n",
      "fatherOccupation                             0\n",
      "admissionGrade                               0\n",
      "displaced                                    0\n",
      "educationalSpecialNeeds                      0\n",
      "debtor                                       0\n",
      "tuitionFeesUpToDate                          0\n",
      "gender                                       0\n",
      "scholarshipHolder                            0\n",
      "ageAtEnrollment                              0\n",
      "international                                0\n",
      "curricularUnits1stSemCredited                0\n",
      "curricularUnits1stSemEnrolled                0\n",
      "curricularUnits1stSemEvaluations             0\n",
      "curricularUnits1stSemApproved                0\n",
      "curricularUnits1stSemGrade                   0\n",
      "curricularUnits1stSemWithoutEvaluations      0\n",
      "curricularUnits2ndSemCredited                0\n",
      "curricularUnits2ndSemEnrolled                0\n",
      "curricularUnits2ndSemEvaluations             0\n",
      "curricularUnits2ndSemApproved                0\n",
      "curricularUnits2ndSemGrade                   0\n",
      "curricularUnits2ndSemWithoutEvaluations      0\n",
      "unemploymentRate                             0\n",
      "inflationRate                                0\n",
      "gdp                                          0\n",
      "target                                       0\n",
      "year                                         0\n",
      "economicStressIndex                          0\n",
      "isEconomyGood                                0\n",
      "normalizedUnemploymentByYear               922\n",
      "dtype: int64\n",
      "\u001b[34m\u001b[3m-------[C]show only columns that have missing values\u001b[0m\n",
      "normalizedUnemploymentByYear    922\n",
      "dtype: int64\n",
      "\u001b[34m\u001b[3m-------[C]check if any missing value exists in the entire dataframe\u001b[0m\n",
      "True\n",
      "\u001b[34m\u001b[3m-------[C]list all rows that contain any nan\u001b[0m\n",
      "      maritalStatus  applicationMode  applicationOrder  course  \\\n",
      "0                 1               17                 5     171   \n",
      "2                 1                1                 5    9070   \n",
      "6                 1                1                 1    9500   \n",
      "7                 1               18                 4    9254   \n",
      "14                1                1                 1    9085   \n",
      "...             ...              ...               ...     ...   \n",
      "4403              1               17                 3    9500   \n",
      "4406              1                1                 1    9070   \n",
      "4407              1                1                 1    9773   \n",
      "4410              1                1                 1    9070   \n",
      "4419              1                1                 6    9773   \n",
      "\n",
      "      daytimeEveningAttendance  previousQualification  \\\n",
      "0                            1                      1   \n",
      "2                            1                      1   \n",
      "6                            1                      1   \n",
      "7                            1                      1   \n",
      "14                           1                      1   \n",
      "...                        ...                    ...   \n",
      "4403                         1                      1   \n",
      "4406                         1                      1   \n",
      "4407                         1                      1   \n",
      "4410                         1                      1   \n",
      "4419                         1                      1   \n",
      "\n",
      "      previousQualificationGrade  nationality  motherQualification  \\\n",
      "0                          122.0            1                   19   \n",
      "2                          122.0            1                   37   \n",
      "6                          142.0            1                   19   \n",
      "7                          119.0            1                   37   \n",
      "14                         149.0            1                   38   \n",
      "...                          ...          ...                  ...   \n",
      "4403                       137.0            1                    1   \n",
      "4406                       145.0            1                    1   \n",
      "4407                       138.0            1                    1   \n",
      "4410                       124.0            1                   37   \n",
      "4419                       125.0            1                    1   \n",
      "\n",
      "      fatherQualification  ...  curricularUnits2ndSemGrade  \\\n",
      "0                      12  ...                    0.000000   \n",
      "2                      37  ...                    0.000000   \n",
      "6                      38  ...                   14.345000   \n",
      "7                      37  ...                    0.000000   \n",
      "14                     37  ...                   12.000000   \n",
      "...                   ...  ...                         ...   \n",
      "4403                    1  ...                   11.262500   \n",
      "4406                   38  ...                   11.333333   \n",
      "4407                   19  ...                   13.285714   \n",
      "4410                   19  ...                   12.500000   \n",
      "4419                    1  ...                   12.666667   \n",
      "\n",
      "      curricularUnits2ndSemWithoutEvaluations  unemploymentRate  \\\n",
      "0                                           0              10.8   \n",
      "2                                           0              10.8   \n",
      "6                                           0              15.5   \n",
      "7                                           0              15.5   \n",
      "14                                          0              10.8   \n",
      "...                                       ...               ...   \n",
      "4403                                        0              15.5   \n",
      "4406                                        0              10.8   \n",
      "4407                                        0              15.5   \n",
      "4410                                        0              10.8   \n",
      "4419                                        0              15.5   \n",
      "\n",
      "      inflationRate   gdp    target  year  economicStressIndex  isEconomyGood  \\\n",
      "0               1.4  1.74   Dropout  2010                10.46              0   \n",
      "2               1.4  1.74   Dropout  2010                10.46              0   \n",
      "6               2.8 -4.06  Graduate  2014                22.36              0   \n",
      "7               2.8 -4.06   Dropout  2014                22.36              0   \n",
      "14              1.4  1.74  Graduate  2010                10.46              0   \n",
      "...             ...   ...       ...   ...                  ...            ...   \n",
      "4403            2.8 -4.06  Graduate  2014                22.36              0   \n",
      "4406            1.4  1.74  Enrolled  2010                10.46              0   \n",
      "4407            2.8 -4.06  Graduate  2014                22.36              0   \n",
      "4410            1.4  1.74  Graduate  2010                10.46              0   \n",
      "4419            2.8 -4.06  Graduate  2014                22.36              0   \n",
      "\n",
      "      normalizedUnemploymentByYear  \n",
      "0                              NaN  \n",
      "2                              NaN  \n",
      "6                              NaN  \n",
      "7                              NaN  \n",
      "14                             NaN  \n",
      "...                            ...  \n",
      "4403                           NaN  \n",
      "4406                           NaN  \n",
      "4407                           NaN  \n",
      "4410                           NaN  \n",
      "4419                           NaN  \n",
      "\n",
      "[922 rows x 41 columns]\n",
      "\u001b[31m\u001b[1m<[SECTION]ECON AND YEAR\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]TARGET\u001b[0m\n",
      "Target unique: ['Dropout' 'Graduate' 'Enrolled']\n",
      "Unmapped target labels: []\n",
      "\u001b[31m\u001b[1m<[SECTION]TARGET\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]PARENT QUALIFICATION AND OCCUPATION\u001b[0m\n",
      "\u001b[31m\u001b[1m<[SECTION]PARENT QUALIFICATION AND OCCUPATION\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]ACADEMIC ACTIVITY AND PERFORMANCE\u001b[0m\n",
      "Fully inactive students: 180\n",
      "\n",
      "Target label distribution for inactive students:\n",
      "target\n",
      "Dropout     77\n",
      "Graduate    75\n",
      "Enrolled    28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Descriptive stats for selected features of inactive students:\n",
      "\n",
      "Target distribution grouped by noAcademicActivity flag:\n",
      "\u001b[31m\u001b[1m<[SECTION]ACADEMIC ACTIVITY AND PERFORMANCE\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]APPLICATION MODE\u001b[0m\n",
      "\u001b[31m\u001b[1m<[SECTION]APPLICATION MODE\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]DROP COLUMNN\u001b[0m\n",
      "\u001b[31m\u001b[1m<[SECTION]DROP COLUMNN\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]SAVE SNAPSHOT\u001b[0m\n",
      "\u001b[31m\u001b[1m<[SECTION]SAVE SNAPSHOT\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]TRAINING\u001b[0m\n",
      "\u001b[31m\u001b[1m<[SECTION]TRAINING\u001b[0m\n",
      "\u001b[31m\u001b[1m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[1m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[32m\u001b[1m>[SECTION]EVALUATE\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 170\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m#2D Scatter Plot (with PCA)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m    172\u001b[0m scatter \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mscatter(X_pca[:, \u001b[38;5;241m0\u001b[39m], X_pca[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39my_pred, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:466\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:503\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    495\u001b[0m     )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2952\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2954\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2956\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1105\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\faceenv\\lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "\n",
    "__________section__________(\"general check\")\n",
    "#check new column names\n",
    "df_rf.rename(columns=conversion_dict, inplace=True)\n",
    "#print(df_rf.columns)\n",
    "\n",
    "_c_(\"check type\")\n",
    "print(df_rf.dtypes[df_rf.dtypes == \"object\"])\n",
    "\n",
    "nanCheck()\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"econ and year\")\n",
    "# Map the tuple of 3 macro features to year\n",
    "df_rf[\"year\"] = df_rf.apply(lambda row: econ_to_year.get((row[\"unemploymentRate\"], row[\"inflationRate\"], row[\"gdp\"])),axis=1)\n",
    "\n",
    "#check missing year\n",
    "print(\"Missing year:\", df_rf[\"year\"].isnull().sum())\n",
    "\n",
    "#EconomicStressIndex\n",
    "df_rf[\"economicStressIndex\"] = df_rf[\"unemploymentRate\"] + df_rf[\"inflationRate\"] - df_rf[\"gdp\"]\n",
    "\n",
    "#Is_Economy_Good binary flag\n",
    "df_rf[\"isEconomyGood\"] = ((df_rf[\"gdp\"] > 1.5) & (df_rf[\"unemploymentRate\"] < 10)).astype(int)\n",
    "\n",
    "#normalizedUnemploymentByYear\n",
    "df_rf[\"normalizedUnemploymentByYear\"] = df_rf.groupby(\"year\")[\"unemploymentRate\"].transform(lambda x: (x - x.mean()) / x.std())\n",
    "nanCheck()\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"target\")\n",
    "#check all row got target\n",
    "print(\"Target unique:\", df_rf[\"target\"].unique())\n",
    "print(\"Unmapped target labels:\", sorted(set(df_rf[\"target\"].dropna().astype(str).str.strip().str.title()) - set(targetMap.keys())))\n",
    "\n",
    "#convert target to targetInt\n",
    "df_rf[\"targetInt\"] = (df_rf[\"target\"].map(targetMap).astype(\"Int64\"))\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"parent qualification and occupation\")\n",
    "# create a new column based on parent qualification mapped to ordinal\n",
    "df_rf[\"motherQualificationOrdinal\"] = df_rf[\"motherQualification\"].map(qualificationOrdinal)\n",
    "df_rf[\"fatherQualificationOrdinal\"] = df_rf[\"fatherQualification\"].map(qualificationOrdinal)\n",
    "\n",
    "# create a new column based on parent income mapped to ordinal\n",
    "df_rf[\"motherOccupationOrdinal\"] = df_rf[\"motherOccupation\"].map(occupationOrdinal)\n",
    "df_rf[\"fatherOccupationOrdinal\"] = df_rf[\"fatherOccupation\"].map(occupationOrdinal)\n",
    "\n",
    "#average parent edu and occupation\n",
    "df_rf[\"avgParentalEducation\"] = df_rf[[\"motherQualificationOrdinal\", \"fatherQualificationOrdinal\"]].mean(axis=1)\n",
    "df_rf[\"avgParentalIncome\"] = df_rf[[\"motherOccupationOrdinal\", \"fatherOccupationOrdinal\"]].mean(axis=1)\n",
    "\n",
    "#parentalDisparity\n",
    "df_rf[\"parentalEduDisparity\"] = abs(df_rf[\"motherQualificationOrdinal\"] - df_rf[\"fatherQualificationOrdinal\"])\n",
    "df_rf[\"parentalIncomeDisparity\"] = abs(df_rf[\"motherOccupationOrdinal\"] - df_rf[\"fatherOccupationOrdinal\"])\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"academic activity and performance\")\n",
    "# Define inactive students (zero academic activity)\n",
    "inactive_mask = (\n",
    "    (df_rf[\"curricularUnits1stSemEnrolled\"] == 0) &\n",
    "    (df_rf[\"curricularUnits2ndSemEnrolled\"] == 0) &\n",
    "    (df_rf[\"curricularUnits1stSemEvaluations\"] == 0) &\n",
    "    (df_rf[\"curricularUnits2ndSemEvaluations\"] == 0) &\n",
    "    (df_rf[\"curricularUnits1stSemGrade\"] == 0) &\n",
    "    (df_rf[\"curricularUnits2ndSemGrade\"] == 0)\n",
    ")\n",
    "\n",
    "# Subset those inactive students\n",
    "inactive_students = df_rf[inactive_mask]\n",
    "\n",
    "# Print how many\n",
    "print(f\"Fully inactive students: {len(inactive_students)}\")\n",
    "\n",
    "# Check their target label distribution\n",
    "print(\"\\nTarget label distribution for inactive students:\")\n",
    "print(inactive_students[\"target\"].value_counts())\n",
    "\n",
    "# Check other features for patterns\n",
    "print(\"\\nDescriptive stats for selected features of inactive students:\")\n",
    "#print(inactive_students[[\"applicationOrder\", \"applicationMode\", \"ageAtEnrollment\", \"scholarshipHolder\", \"international\", \"displaced\", \"motherQualification\", \"fatherOccupation\", \"year\", \"isEconomyGood\"]].describe(include=\"all\"))\n",
    "\n",
    "# Add binary flag to main dataframe\n",
    "df_rf[\"noAcademicActivity\"] = inactive_mask.astype(int)\n",
    "\n",
    "# See how 'noAcademicActivity' affects the target label\n",
    "print(\"\\nTarget distribution grouped by noAcademicActivity flag:\")\n",
    "#print(df_rf.groupby(\"noAcademicActivity\")[\"target\"].value_counts(normalize=True))\n",
    "\n",
    "#Approved Rate\n",
    "df_rf[\"approvedRate1stSem\"] = df_rf[\"curricularUnits1stSemApproved\"] / df_rf[\"curricularUnits1stSemEnrolled\"].replace(0, np.nan)\n",
    "df_rf[\"approvedRate2ndSem\"] = df_rf[\"curricularUnits2ndSemApproved\"] / df_rf[\"curricularUnits2ndSemEnrolled\"].replace(0, np.nan)\n",
    "\n",
    "# Performance Index\n",
    "df_rf[\"performanceIndex1stSem\"] = df_rf[\"approvedRate1stSem\"] * df_rf[\"curricularUnits1stSemGrade\"]\n",
    "df_rf[\"performanceIndex2ndSem\"] = df_rf[\"approvedRate2ndSem\"] * df_rf[\"curricularUnits2ndSemGrade\"]\n",
    "\n",
    "#CreditLoadReduction\n",
    "df_rf[\"creditLoadReduction1stSem\"] = df_rf[\"curricularUnits1stSemCredited\"] / df_rf[\"curricularUnits1stSemEnrolled\"].replace(0, np.nan)\n",
    "df_rf[\"creditLoadReduction2ndSem\"] = df_rf[\"curricularUnits2ndSemCredited\"] / df_rf[\"curricularUnits2ndSemEnrolled\"].replace(0, np.nan)\n",
    "\n",
    "# Evalution rate\n",
    "df_rf[\"evalRate1stSem\"] = df_rf[\"curricularUnits1stSemEvaluations\"] / (df_rf[\"curricularUnits1stSemEvaluations\"] + df_rf[\"curricularUnits1stSemWithoutEvaluations\"])\n",
    "df_rf[\"evalRate2ndSem\"] = df_rf[\"curricularUnits2ndSemEvaluations\"] / (df_rf[\"curricularUnits2ndSemEvaluations\"] + df_rf[\"curricularUnits2ndSemWithoutEvaluations\"])\n",
    "\n",
    "#noAcademicActivity flag student\n",
    "df_rf[\"noAcademicActivity\"] = inactive_mask.astype(int)\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"Application Mode\")\n",
    "# Application Mode shifted cause 0 is first choice unsuitable\n",
    "df_rf[\"applicationOrderShifted\"] = df_rf[\"applicationOrder\"] + 1\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"drop columnn\")\n",
    "columns_to_drop = [\n",
    "    \"target\",\n",
    "    \"motherQualification\",\n",
    "    \"fatherQualification\",\n",
    "    \"motherOccupation\",\n",
    "    \"fatherOccupation\",\n",
    "    \"applicationOrder\"\n",
    "]\n",
    "\n",
    "df_model = df_rf.drop(columns=columns_to_drop)\n",
    "\n",
    "columns_optional = [\n",
    "    \"unemploymentRate\", \"inflationRate\", \"gdp\",\n",
    "    \"curricularUnits1stSemEnrolled\", \"curricularUnits2ndSemEnrolled\",\n",
    "    \"curricularUnits1stSemApproved\", \"curricularUnits2ndSemApproved\",\n",
    "    \"curricularUnits1stSemGrade\", \"curricularUnits2ndSemGrade\",\n",
    "    \"curricularUnits1stSemCredited\", \"curricularUnits2ndSemCredited\",\n",
    "    \"curricularUnits1stSemEvaluations\", \"curricularUnits1stSemWithoutEvaluations\",\n",
    "    \"curricularUnits2ndSemEvaluations\", \"curricularUnits2ndSemWithoutEvaluations\"\n",
    "]\n",
    "\n",
    "# Drop these only if confirmed redundant\n",
    "#df_model = df_model.drop(columns=columns_optional)\n",
    "\n",
    "#df = df_rf.drop(\"columnName\", axis=1)\n",
    "#axis=1  means you're dropping a column (not a row)\n",
    "#df = df_rf.drop(5, axis=0)\n",
    "#df = df_rf.drop(5, axis=0)\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"Save snapshot\")\n",
    "df_rf.to_csv(\"student_dataset_engineered.csv\", index=False)\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"training\")\n",
    "X = df_model.drop(columns=[\"targetInt\"])\n",
    "y = df_model[\"targetInt\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Train the Random Forest Model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    max_depth=None, \n",
    "    random_state=42, \n",
    "    class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "__________section__________()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__________section__________(\"evaluate\")\n",
    "\n",
    "#2D Scatter Plot (with PCA)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, cmap='viridis', alpha=0.7)\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"2D PCA Scatter Plot (Predicted Classes)\")\n",
    "plt.colorbar(scatter, ticks=[0, 1, 2], label=\"Predicted Class\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Feature Importance Bar Plot\n",
    "importances = model.feature_importances_\n",
    "features = X.columns if hasattr(X, 'columns') else [f'Feature {i}' for i in range(X.shape[1])]\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(np.array(features)[indices], importances[indices])\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Confusion Matrix Heatmap\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [\"Dropout\", \"Enrolled\", \"Graduate\"]\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "#Decision Boundary (2D only)\n",
    "# Reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(X_2d, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Train lightweight RF model\n",
    "rf_2d = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_2d.fit(X_train_2d, y_train_2d)\n",
    "# Plot decision boundary\n",
    "plot_decision_regions(X_test_2d, y_test_2d.to_numpy(), clf=rf_2d, legend=2)\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"Decision Boundary (2D PCA Projection)\")\n",
    "plt.show()\n",
    "\n",
    "#Prediction Confidence Histogram\n",
    "probs = model.predict_proba(X_test)\n",
    "confidences = probs.max(axis=1)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(confidences, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Prediction Confidence\")\n",
    "plt.ylabel(\"Number of Predictions\")\n",
    "plt.title(\"Distribution of Prediction Confidence\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Dropout\", \"Enrolled\", \"Graduate\"]))\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "importances = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "sns.barplot(x=importances, y=features)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Dropout\", \"Enrolled\", \"Graduate\"], yticklabels=[\"Dropout\", \"Enrolled\", \"Graduate\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "__________section__________()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a16ecc-449d-4431-91bd-b76be03c3396",
   "metadata": {},
   "source": [
    "# Next\n",
    "[TableOfContents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dc3a9-b739-4ea9-8313-26564b0fe84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "### ----------\n",
    " Random Forest Key Parameters\n",
    "\n",
    " n_estimators=100\n",
    "Number of trees in the forest.\n",
    "More trees = better generalization, but longer training time.\n",
    "Rule of thumb: start with 100300; increase if your dataset is large.\n",
    "\n",
    " max_depth=None\n",
    "How deep each tree is allowed to grow.\n",
    "None means nodes are expanded until pure or until all leaves contain < min_samples_split.\n",
    "Deeper trees  more complex rules  risk of overfitting.\n",
    "\n",
    " random_state=42\n",
    "Makes the model reproducible.\n",
    "Fixes the randomness so you get the same result every time you run it.\n",
    "\n",
    " class_weight='balanced'\n",
    "Adjusts weights inversely proportional to class frequencies.\n",
    "Useful when classes are imbalanced (e.g. too many graduates vs. few dropouts).\n",
    "Other option: class_weight={0:2, 1:1, 2:1} (manual tuning).\n",
    "### ----------\n",
    " X (IInput Features)  Conditions & Types\n",
    "Random Forest can handle mixed data types, but you must still preprocess appropriately:\n",
    "\n",
    "Feature Type\tExamples\tNotes\n",
    " Numeric\tAge, GPA, Grade average\tOK without encoding\n",
    " Binary\tGender (0/1), Scholarship (Yes/No)\tConvert Yes/No to 0/1\n",
    " Categorical\tCourse Name, Nationality, Fathers Job\tMust be encoded\n",
    " Text\tFree-text essay, names\tMust be vectorized or dropped\n",
    " High-cardinality\t100+ unique categories (e.g. 500 job titles)\tRisk of overfitting  avoid or group them\n",
    "### ----------\n",
    " How to Encode Categorical Columns:\n",
    "Use LabelEncoder or pd.get_dummies() for most.\n",
    "Avoid keeping strings directly.\n",
    "### ----------\n",
    " y (Target Variable)  Conditions\n",
    "Requirement\tExample\n",
    " Must be categorical or discrete\te.g., 0 = dropout, 1 = enrolled, 2 = graduated\n",
    " No continuous/float values\tUse regression instead of classification\n",
    "Can be:\tintegers, strings (if using LabelEncoder)\n",
    "### ----------\n",
    " What to Avoid\n",
    "Mistake\tWhy Its a Problem\n",
    "Keeping raw strings or object dtype\tTrees can't handle text directly\n",
    "Too many missing values\tCauses unreliable splits\n",
    "No feature scaling\tNot needed for trees  unlike SVM/LogReg\n",
    "Unbalanced classes + no class_weight\tModel may ignore minority class\n",
    "Using irrelevant or highly correlated features\tAdds noise; harms performance\n",
    "Data leakage\tDon't include features that leak the target (e.g. final grade when predicting dropout)\n",
    "### ----------\n",
    " What to Aim for in X (Input)\n",
    "Best Practice\tDescription\n",
    "Cleaned & preprocessed\tNo NaN, strings, or irrelevant cols\n",
    "Compact\t10100 features is good starting point\n",
    "Encoded properly\tCategorical  OneHot / LabelEncoded\n",
    "Balanced information\tAvoid too many similar/redundant features\n",
    "Derived Features\tFeature engineering like ratios or differences can help (e.g. \"approved/enrolled\")\n",
    "### ----------\n",
    " Other Things You Should Know\n",
    " Evaluation Metrics (for multi-class)\n",
    "Use more than just accuracy:\n",
    "classification_report(): shows precision, recall, f1-score per class\n",
    "confusion_matrix(): shows how each class is predicted\n",
    "Visual tools: confusion matrix heatmap, feature importance bar chart\n",
    " Feature Importance\n",
    "Random Forest can rank features by importance:\n",
    "model.feature_importances_\n",
    "This helps you:\n",
    "Understand what the model \"cares about\"\n",
    "Reduce features for faster training\n",
    " Hyperparameter Tuning (optional)\n",
    "Use GridSearchCV to find the best combo of:\n",
    "n_estimators, max_depth, min_samples_split, max_features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735cd9b-ee45-4046-8e6c-0d8840934bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. GridSearchCV  How to Use\n",
    "\n",
    " GridSearchCV helps you find the best hyperparameters by trying out multiple combinations and cross-validating them.\n",
    "\n",
    " Example for Random Forest:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ef891-82a9-4239-b6c0-d8a7f4c67652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bd1fa-7965-4469-b0f4-036a58d22452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862d4e1-e0ea-4696-933d-69098067748b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ae971-094d-41f3-8b16-b43160a13595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
